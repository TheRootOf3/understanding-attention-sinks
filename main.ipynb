{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aszab/EDU/CAM/modules/L46/project/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    Gemma2ForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    HybridCache,\n",
    "    LlamaForCausalLM,\n",
    "    LlamaTokenizerFast,\n",
    "    GPT2LMHeadModel,\n",
    "    GPT2TokenizerFast,\n",
    ")\n",
    "\n",
    "\n",
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/Users/aszab/repos/models/gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path).to(device)\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(model_path)\n",
    "\n",
    "if model.config.pad_token_id is None:\n",
    "    model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'PreTrainedTokenizerFast'. \n",
      "The class this function is called from is 'LlamaTokenizerFast'.\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/Users/aszab/repos/models/Llama-3.2-1B\"\n",
    "model = LlamaForCausalLM.from_pretrained(model_path).to(device)\n",
    "\n",
    "tokenizer = LlamaTokenizerFast.from_pretrained(model_path)\n",
    "\n",
    "if model.config.pad_token_id is None:\n",
    "    model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/Users/aszab/repos/models/gemma-2-2b\"\n",
    "model = Gemma2ForCausalLM.from_pretrained(model_path).to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Hello, my dog is cute and\", return_tensors=\"pt\").to(device)\n",
    "\n",
    "outputs = model(\n",
    "    **inputs,\n",
    "    # pad_token_id=model.config.pad_token_id\n",
    "    labels=inputs[\"input_ids\"],\n",
    ")\n",
    "past_key_values = outputs.past_key_values\n",
    "pred_token_idx = outputs.logits[:, -1, :].argmax(dim=-1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4, 5, 6, 7]], device='mps:0')\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7], device='mps:0')\n",
      "(tensor([[[ 1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000],\n",
      "         [ 0.5403,  0.7878,  0.9046,  0.9576,  0.9813,  0.9917,  0.9964,\n",
      "           0.9984,  0.9993,  0.9997,  0.9999,  0.9999,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  0.5403,  0.7878,  0.9046,\n",
      "           0.9576,  0.9813,  0.9917,  0.9964,  0.9984,  0.9993,  0.9997,\n",
      "           0.9999,  0.9999,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000],\n",
      "         [-0.4161,  0.2412,  0.6366,  0.8340,  0.9257,  0.9671,  0.9855,\n",
      "           0.9936,  0.9972,  0.9988,  0.9995,  0.9998,  0.9999,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000, -0.4161,  0.2412,  0.6366,\n",
      "           0.8340,  0.9257,  0.9671,  0.9855,  0.9936,  0.9972,  0.9988,\n",
      "           0.9995,  0.9998,  0.9999,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000],\n",
      "         [-0.9900, -0.4078,  0.2471,  0.6397,  0.8355,  0.9264,  0.9674,\n",
      "           0.9856,  0.9936,  0.9972,  0.9988,  0.9995,  0.9998,  0.9999,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000, -0.9900, -0.4078,  0.2471,\n",
      "           0.6397,  0.8355,  0.9264,  0.9674,  0.9856,  0.9936,  0.9972,\n",
      "           0.9988,  0.9995,  0.9998,  0.9999,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000],\n",
      "         [-0.6536, -0.8837, -0.1895,  0.3912,  0.7139,  0.8704,  0.9422,\n",
      "           0.9744,  0.9887,  0.9950,  0.9978,  0.9990,  0.9996,  0.9998,\n",
      "           0.9999,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000, -0.6536, -0.8837, -0.1895,\n",
      "           0.3912,  0.7139,  0.8704,  0.9422,  0.9744,  0.9887,  0.9950,\n",
      "           0.9978,  0.9990,  0.9996,  0.9998,  0.9999,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000],\n",
      "         [ 0.2837, -0.9845, -0.5900,  0.1094,  0.5656,  0.8000,  0.9102,\n",
      "           0.9601,  0.9824,  0.9922,  0.9966,  0.9985,  0.9993,  0.9997,\n",
      "           0.9999,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  0.2837, -0.9845, -0.5900,\n",
      "           0.1094,  0.5656,  0.8000,  0.9102,  0.9601,  0.9824,  0.9922,\n",
      "           0.9966,  0.9985,  0.9993,  0.9997,  0.9999,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000],\n",
      "         [ 0.9602, -0.6675, -0.8779, -0.1816,  0.3961,  0.7164,  0.8716,\n",
      "           0.9427,  0.9747,  0.9888,  0.9951,  0.9978,  0.9990,  0.9996,\n",
      "           0.9998,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  0.9602, -0.6675, -0.8779,\n",
      "          -0.1816,  0.3961,  0.7164,  0.8716,  0.9427,  0.9747,  0.9888,\n",
      "           0.9951,  0.9978,  0.9990,  0.9996,  0.9998,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000],\n",
      "         [ 0.7539, -0.0671, -0.9983, -0.4572,  0.2117,  0.6210,  0.8266,\n",
      "           0.9223,  0.9656,  0.9848,  0.9933,  0.9970,  0.9987,  0.9994,\n",
      "           0.9997,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  0.7539, -0.0671, -0.9983,\n",
      "          -0.4572,  0.2117,  0.6210,  0.8266,  0.9223,  0.9656,  0.9848,\n",
      "           0.9933,  0.9970,  0.9987,  0.9994,  0.9997,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000]]], device='mps:0'), tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 8.4147e-01,  6.1596e-01,  4.2627e-01,  2.8809e-01,  1.9271e-01,\n",
      "           1.2833e-01,  8.5293e-02,  5.6639e-02,  3.7597e-02,  2.4953e-02,\n",
      "           1.6560e-02,  1.0989e-02,  7.2926e-03,  4.8394e-03,  3.2114e-03,\n",
      "           1.2905e-03,  4.2956e-04,  9.7083e-05,  1.9462e-05,  1.2915e-05,\n",
      "           8.5703e-06,  5.6872e-06,  3.7741e-06,  2.5045e-06,  1.6620e-06,\n",
      "           1.1029e-06,  7.3187e-07,  4.8567e-07,  3.2229e-07,  2.1387e-07,\n",
      "           1.4193e-07,  9.4183e-08,  8.4147e-01,  6.1596e-01,  4.2627e-01,\n",
      "           2.8809e-01,  1.9271e-01,  1.2833e-01,  8.5293e-02,  5.6639e-02,\n",
      "           3.7597e-02,  2.4953e-02,  1.6560e-02,  1.0989e-02,  7.2926e-03,\n",
      "           4.8394e-03,  3.2114e-03,  1.2905e-03,  4.2956e-04,  9.7083e-05,\n",
      "           1.9462e-05,  1.2915e-05,  8.5703e-06,  5.6872e-06,  3.7741e-06,\n",
      "           2.5045e-06,  1.6620e-06,  1.1029e-06,  7.3187e-07,  4.8567e-07,\n",
      "           3.2229e-07,  2.1387e-07,  1.4193e-07,  9.4183e-08],\n",
      "         [ 9.0930e-01,  9.7048e-01,  7.7121e-01,  5.5175e-01,  3.7819e-01,\n",
      "           2.5454e-01,  1.6997e-01,  1.1310e-01,  7.5141e-02,  4.9890e-02,\n",
      "           3.3115e-02,  2.1977e-02,  1.4585e-02,  9.6787e-03,  6.4228e-03,\n",
      "           2.5811e-03,  8.5911e-04,  1.9417e-04,  3.8923e-05,  2.5830e-05,\n",
      "           1.7141e-05,  1.1374e-05,  7.5481e-06,  5.0089e-06,  3.3239e-06,\n",
      "           2.2058e-06,  1.4637e-06,  9.7135e-07,  6.4459e-07,  4.2775e-07,\n",
      "           2.8385e-07,  1.8837e-07,  9.0930e-01,  9.7048e-01,  7.7121e-01,\n",
      "           5.5175e-01,  3.7819e-01,  2.5454e-01,  1.6997e-01,  1.1310e-01,\n",
      "           7.5141e-02,  4.9890e-02,  3.3115e-02,  2.1977e-02,  1.4585e-02,\n",
      "           9.6787e-03,  6.4228e-03,  2.5811e-03,  8.5911e-04,  1.9417e-04,\n",
      "           3.8923e-05,  2.5830e-05,  1.7141e-05,  1.1374e-05,  7.5481e-06,\n",
      "           5.0089e-06,  3.3239e-06,  2.2058e-06,  1.4637e-06,  9.7135e-07,\n",
      "           6.4459e-07,  4.2775e-07,  2.8385e-07,  1.8837e-07],\n",
      "         [ 1.4112e-01,  9.1309e-01,  9.6899e-01,  7.6862e-01,  5.4950e-01,\n",
      "           3.7654e-01,  2.5340e-01,  1.6919e-01,  1.1258e-01,  7.4796e-02,\n",
      "           4.9661e-02,  3.2963e-02,  2.1876e-02,  1.4518e-02,  9.6342e-03,\n",
      "           3.8716e-03,  1.2887e-03,  2.9125e-04,  5.8385e-05,  3.8744e-05,\n",
      "           2.5711e-05,  1.7062e-05,  1.1322e-05,  7.5134e-06,  4.9859e-06,\n",
      "           3.3087e-06,  2.1956e-06,  1.4570e-06,  9.6688e-07,  6.4162e-07,\n",
      "           4.2578e-07,  2.8255e-07,  1.4112e-01,  9.1309e-01,  9.6899e-01,\n",
      "           7.6862e-01,  5.4950e-01,  3.7654e-01,  2.5340e-01,  1.6919e-01,\n",
      "           1.1258e-01,  7.4796e-02,  4.9661e-02,  3.2963e-02,  2.1876e-02,\n",
      "           1.4518e-02,  9.6342e-03,  3.8716e-03,  1.2887e-03,  2.9125e-04,\n",
      "           5.8385e-05,  3.8744e-05,  2.5711e-05,  1.7062e-05,  1.1322e-05,\n",
      "           7.5134e-06,  4.9859e-06,  3.3087e-06,  2.1956e-06,  1.4570e-06,\n",
      "           9.6688e-07,  6.4162e-07,  4.2578e-07,  2.8255e-07],\n",
      "         [-7.5680e-01,  4.6814e-01,  9.8188e-01,  9.2033e-01,  7.0021e-01,\n",
      "           4.9232e-01,  3.3498e-01,  2.2474e-01,  1.4986e-01,  9.9656e-02,\n",
      "           6.6193e-02,  4.3944e-02,  2.9167e-02,  1.9356e-02,  1.2845e-02,\n",
      "           5.1622e-03,  1.7182e-03,  3.8833e-04,  7.7847e-05,  5.1659e-05,\n",
      "           3.4281e-05,  2.2749e-05,  1.5096e-05,  1.0018e-05,  6.6479e-06,\n",
      "           4.4115e-06,  2.9275e-06,  1.9427e-06,  1.2892e-06,  8.5550e-07,\n",
      "           5.6771e-07,  3.7673e-07, -7.5680e-01,  4.6814e-01,  9.8188e-01,\n",
      "           9.2033e-01,  7.0021e-01,  4.9232e-01,  3.3498e-01,  2.2474e-01,\n",
      "           1.4986e-01,  9.9656e-02,  6.6193e-02,  4.3944e-02,  2.9167e-02,\n",
      "           1.9356e-02,  1.2845e-02,  5.1622e-03,  1.7182e-03,  3.8833e-04,\n",
      "           7.7847e-05,  5.1659e-05,  3.4281e-05,  2.2749e-05,  1.5096e-05,\n",
      "           1.0018e-05,  6.6479e-06,  4.4115e-06,  2.9275e-06,  1.9427e-06,\n",
      "           1.2892e-06,  8.5550e-07,  5.6771e-07,  3.7673e-07],\n",
      "         [-9.5892e-01, -1.7550e-01,  8.0742e-01,  9.9399e-01,  8.2467e-01,\n",
      "           5.9995e-01,  4.1413e-01,  2.7957e-01,  1.8692e-01,  1.2445e-01,\n",
      "           8.2708e-02,  5.4920e-02,  3.6455e-02,  2.4195e-02,  1.6057e-02,\n",
      "           6.4527e-03,  2.1478e-03,  4.8541e-04,  9.7308e-05,  6.4574e-05,\n",
      "           4.2851e-05,  2.8436e-05,  1.8870e-05,  1.2522e-05,  8.3098e-06,\n",
      "           5.5144e-06,  3.6594e-06,  2.4284e-06,  1.6115e-06,  1.0694e-06,\n",
      "           7.0964e-07,  4.7092e-07, -9.5892e-01, -1.7550e-01,  8.0742e-01,\n",
      "           9.9399e-01,  8.2467e-01,  5.9995e-01,  4.1413e-01,  2.7957e-01,\n",
      "           1.8692e-01,  1.2445e-01,  8.2708e-02,  5.4920e-02,  3.6455e-02,\n",
      "           2.4195e-02,  1.6057e-02,  6.4527e-03,  2.1478e-03,  4.8541e-04,\n",
      "           9.7308e-05,  6.4574e-05,  4.2851e-05,  2.8436e-05,  1.8870e-05,\n",
      "           1.2522e-05,  8.3098e-06,  5.5144e-06,  3.6594e-06,  2.4284e-06,\n",
      "           1.6115e-06,  1.0694e-06,  7.0964e-07,  4.7092e-07],\n",
      "         [-2.7942e-01, -7.4465e-01,  4.7889e-01,  9.8338e-01,  9.1821e-01,\n",
      "           6.9766e-01,  4.9026e-01,  3.3350e-01,  2.2373e-01,  1.4917e-01,\n",
      "           9.9199e-02,  6.5889e-02,  4.3742e-02,  2.9032e-02,  1.9267e-02,\n",
      "           7.7432e-03,  2.5773e-03,  5.8250e-04,  1.1677e-04,  7.7489e-05,\n",
      "           5.1422e-05,  3.4123e-05,  2.2644e-05,  1.5027e-05,  9.9718e-06,\n",
      "           6.6173e-06,  4.3912e-06,  2.9140e-06,  1.9338e-06,  1.2832e-06,\n",
      "           8.5156e-07,  5.6510e-07, -2.7942e-01, -7.4465e-01,  4.7889e-01,\n",
      "           9.8338e-01,  9.1821e-01,  6.9766e-01,  4.9026e-01,  3.3350e-01,\n",
      "           2.2373e-01,  1.4917e-01,  9.9199e-02,  6.5889e-02,  4.3742e-02,\n",
      "           2.9032e-02,  1.9267e-02,  7.7432e-03,  2.5773e-03,  5.8250e-04,\n",
      "           1.1677e-04,  7.7489e-05,  5.1422e-05,  3.4123e-05,  2.2644e-05,\n",
      "           1.5027e-05,  9.9718e-06,  6.6173e-06,  4.3912e-06,  2.9140e-06,\n",
      "           1.9338e-06,  1.2832e-06,  8.5156e-07,  5.6510e-07],\n",
      "         [ 6.5699e-01, -9.9774e-01,  5.8992e-02,  8.8938e-01,  9.7733e-01,\n",
      "           7.8383e-01,  5.6281e-01,  3.8637e-01,  2.6021e-01,  1.7380e-01,\n",
      "           1.1566e-01,  7.6851e-02,  5.1026e-02,  3.3869e-02,  2.2478e-02,\n",
      "           9.0337e-03,  3.0069e-03,  6.7958e-04,  1.3623e-04,  9.0403e-05,\n",
      "           5.9992e-05,  3.9811e-05,  2.6418e-05,  1.7531e-05,  1.1634e-05,\n",
      "           7.7202e-06,  5.1231e-06,  3.3997e-06,  2.2561e-06,  1.4971e-06,\n",
      "           9.9349e-07,  6.5928e-07,  6.5699e-01, -9.9774e-01,  5.8992e-02,\n",
      "           8.8938e-01,  9.7733e-01,  7.8383e-01,  5.6281e-01,  3.8637e-01,\n",
      "           2.6021e-01,  1.7380e-01,  1.1566e-01,  7.6851e-02,  5.1026e-02,\n",
      "           3.3869e-02,  2.2478e-02,  9.0337e-03,  3.0069e-03,  6.7958e-04,\n",
      "           1.3623e-04,  9.0403e-05,  5.9992e-05,  3.9811e-05,  2.6418e-05,\n",
      "           1.7531e-05,  1.1634e-05,  7.7202e-06,  5.1231e-06,  3.3997e-06,\n",
      "           2.2561e-06,  1.4971e-06,  9.9349e-07,  6.5928e-07]]],\n",
      "       device='mps:0'))\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"Hello, my dog is cute and\", return_tensors=\"pt\").to(device)\n",
    "\n",
    "outputs = model(\n",
    "    **inputs,\n",
    "    # pad_token_id=model.config.pad_token_id\n",
    "    labels=inputs[\"input_ids\"],\n",
    ")\n",
    "past_key_values = outputs.past_key_values\n",
    "pred_token_idx = outputs.logits[:, -1, :].argmax(dim=-1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_key_values[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 8, 64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_key_values[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple of tuples. This is deprecated and will be removed in v4.47. Please convert your cache or use an appropriate `Cache` class (https://huggingface.co/docs/transformers/kv_cache#legacy-cache-format)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8]], device='mps:0')\n",
      "tensor([8], device='mps:0')\n",
      "(tensor([[[-0.1455,  0.5617, -0.9282, -0.6940,  0.0194,  0.5152,  0.7756,\n",
      "           0.8990,  0.9551,  0.9801,  0.9912,  0.9961,  0.9983,  0.9993,\n",
      "           0.9997,  0.9999,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000, -0.1455,  0.5617, -0.9282,\n",
      "          -0.6940,  0.0194,  0.5152,  0.7756,  0.8990,  0.9551,  0.9801,\n",
      "           0.9912,  0.9961,  0.9983,  0.9993,  0.9997,  0.9999,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,\n",
      "           1.0000]]], device='mps:0'), tensor([[[ 9.8936e-01, -8.2735e-01, -3.7216e-01,  7.1998e-01,  9.9981e-01,\n",
      "           8.5704e-01,  6.3126e-01,  4.3799e-01,  2.9633e-01,  1.9832e-01,\n",
      "           1.3210e-01,  8.7803e-02,  5.8308e-02,  3.8706e-02,  2.5689e-02,\n",
      "           1.0324e-02,  3.4364e-03,  7.7666e-04,  1.5569e-04,  1.0332e-04,\n",
      "           6.8562e-05,  4.5498e-05,  3.0192e-05,  2.0036e-05,  1.3296e-05,\n",
      "           8.8231e-06,  5.8550e-06,  3.8854e-06,  2.5783e-06,  1.7110e-06,\n",
      "           1.1354e-06,  7.5346e-07,  9.8936e-01, -8.2735e-01, -3.7216e-01,\n",
      "           7.1998e-01,  9.9981e-01,  8.5704e-01,  6.3126e-01,  4.3799e-01,\n",
      "           2.9633e-01,  1.9832e-01,  1.3210e-01,  8.7803e-02,  5.8308e-02,\n",
      "           3.8706e-02,  2.5689e-02,  1.0324e-02,  3.4364e-03,  7.7666e-04,\n",
      "           1.5569e-04,  1.0332e-04,  6.8562e-05,  4.5498e-05,  3.0192e-05,\n",
      "           2.0036e-05,  1.3296e-05,  8.8231e-06,  5.8550e-06,  3.8854e-06,\n",
      "           2.5783e-06,  1.7110e-06,  1.1354e-06,  7.5346e-07]]],\n",
      "       device='mps:0'))\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"really \", return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(\n",
    "        inputs[\"input_ids\"][:, -1:],\n",
    "        # pad_token_id=model.config.pad_token_id\n",
    "        past_key_values=past_key_values,\n",
    "        use_cache=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(outputs.logits[:, -1, :].argmax(dim=-1).unsqueeze(1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_token_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = load_dataset(\n",
    "    \"wikitext\", \"wikitext-2-raw-v1\", split=\"test\", cache_dir=\"~/repos/datasets\"\n",
    ")\n",
    "encodings = tokenizer(\"\\n\\n\".join(test[\"text\"]), return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_key_values[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Attention, Window Attention, Sink Attention (`broken` - without positional encoding shift!)\n",
    "\n",
    "- For dense attention set `kv_cache_size=-1`, `sink_attn_tks=0`.\n",
    "- For window attention set `kv_cache_size` to desired max cache length value and `sink_attn_tks=0`.\n",
    "- For sink attention set both `kv_cache_size` and `sink_attn_tks` to desired values.\n",
    "\n",
    "`chunk_len` specifies the maximum length of an evaluation sequence. E.g. `chunk_len=5` computes over `A B C D E` F G H I J K\n",
    "\n",
    "`num_passes` specifies the max number of PPL computations over a sequence of length `chunk_len`. \n",
    "\n",
    "`shift_len` specifies the number of tokens the main sequence is shifted by to compute perplexity for the next pass.\n",
    "\n",
    "E.g. `num_passes=3, chunk_len=5, shift_len=2` computes over:\n",
    "- `A B C D E` F G H I J K\n",
    "- A B `C D E F G` H I J K\n",
    "- A B C D `E F G H I` J K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encodings.input_ids[:, :10])\n",
    "\n",
    "max_seq_len = encodings.input_ids.size(1)\n",
    "\n",
    "num_passes = 1\n",
    "chunk_len = 1200\n",
    "shift_len = 50\n",
    "\n",
    "kv_cache_size = 256  # -1 means infinite cache\n",
    "sink_attn_tks = 4\n",
    "\n",
    "assert num_passes * chunk_len <= max_seq_len\n",
    "seq_len = shift_len * num_passes\n",
    "print(f\"chunk_len: {chunk_len}\")\n",
    "\n",
    "global_nlls = []\n",
    "global_generation_time = []\n",
    "global_past_key_values_size = []\n",
    "loss_fn = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "\n",
    "for begin_idx in range(0, seq_len, shift_len):\n",
    "    end_idx = min(begin_idx + chunk_len, max_seq_len)\n",
    "    print(f\"{begin_idx=}, {end_idx=}\")\n",
    "\n",
    "    pbar = tqdm(range(begin_idx, end_idx - 1))\n",
    "\n",
    "    if isinstance(model, Gemma2ForCausalLM):\n",
    "        past_key_values = HybridCache(\n",
    "            config=model.config,\n",
    "            batch_size=1,\n",
    "            max_cache_len=chunk_len,\n",
    "            device=model.device,\n",
    "            dtype=model.dtype,\n",
    "        )\n",
    "    else:\n",
    "        past_key_values = None\n",
    "\n",
    "    nlls = []\n",
    "    generation_time = []\n",
    "    past_key_values_size = []\n",
    "\n",
    "    for idx in pbar:\n",
    "        input_ids = encodings.input_ids[:, idx : idx + 1].to(device)\n",
    "        with torch.no_grad():\n",
    "\n",
    "            start_time = time.time()\n",
    "            outputs = model(\n",
    "                input_ids,\n",
    "                past_key_values=past_key_values,\n",
    "                use_cache=True,\n",
    "            )\n",
    "\n",
    "            generation_time.append(time.time() - start_time)\n",
    "\n",
    "            logits = outputs.logits.view(-1, model.config.vocab_size)\n",
    "            label = encodings.input_ids[:, idx + 1 : idx + 2].to(logits.device).view(-1)\n",
    "            neg_log_likelihood = loss_fn(logits, label)\n",
    "            past_key_values = outputs.past_key_values\n",
    "\n",
    "            # cache eviction\n",
    "            if kv_cache_size != -1 and not isinstance(past_key_values, HybridCache):\n",
    "                if past_key_values[0][0].shape[2] >= kv_cache_size:\n",
    "                    past_key_values = [\n",
    "                        [\n",
    "                            torch.cat(\n",
    "                                [\n",
    "                                    param[:, :, 0:sink_attn_tks, :],\n",
    "                                    param[:, :, -(kv_cache_size - sink_attn_tks) :, :],\n",
    "                                ],\n",
    "                                2,\n",
    "                            )\n",
    "                            for param in head\n",
    "                        ]\n",
    "                        for head in past_key_values\n",
    "                    ]\n",
    "\n",
    "            # memory measurements\n",
    "            if isinstance(model, Gemma2ForCausalLM):\n",
    "                past_key_values_size.append(\n",
    "                    sum(\n",
    "                        sum([p_i.numel() * p_i.element_size() for p_i in p])\n",
    "                        for p in [\n",
    "                            *past_key_values.key_cache,\n",
    "                            *past_key_values.value_cache,\n",
    "                        ]\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                past_key_values_size.append(\n",
    "                    sum(\n",
    "                        sum([p_i.numel() * p_i.element_size() for p_i in p])\n",
    "                        for p in past_key_values\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            # clean apple mps cache (for some reason it does not flush automatically)\n",
    "            if torch.backends.mps.is_available():\n",
    "                torch.mps.empty_cache()\n",
    "\n",
    "        nlls.append(neg_log_likelihood)\n",
    "        pbar.set_description(\n",
    "            f\"nll: {neg_log_likelihood.item():.2f}, ppl: {torch.exp(neg_log_likelihood).item():.2f}\"\n",
    "        )\n",
    "    global_nlls.append(nlls)\n",
    "    global_generation_time.append(generation_time)\n",
    "    global_past_key_values_size.append(past_key_values_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding window with recomputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encodings.input_ids[:, :10])\n",
    "\n",
    "max_seq_len = encodings.input_ids.size(1)\n",
    "\n",
    "num_passes = 1\n",
    "chunk_len = 2048\n",
    "shift_len = 50\n",
    "kv_cache_size = 512\n",
    "\n",
    "assert num_passes * chunk_len <= max_seq_len\n",
    "seq_len = shift_len * num_passes\n",
    "print(f\"chunk_len: {chunk_len}\")\n",
    "\n",
    "global_nlls = []\n",
    "global_generation_time = []\n",
    "global_past_key_values_size = []\n",
    "loss_fn = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "\n",
    "for begin_idx in range(0, seq_len, shift_len):\n",
    "    end_idx = min(begin_idx + chunk_len, max_seq_len)\n",
    "    print(f\"{begin_idx=}, {end_idx=}\")\n",
    "\n",
    "    pbar = tqdm(range(begin_idx, end_idx - 1))\n",
    "\n",
    "    nlls = []\n",
    "    generation_time = []\n",
    "    past_key_values_size = []\n",
    "\n",
    "    for idx in pbar:\n",
    "        input_ids = encodings.input_ids[:, max(0, idx - kv_cache_size) : idx + 1].to(\n",
    "            device\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "\n",
    "            start_time = time.time()\n",
    "            outputs = model(\n",
    "                input_ids,\n",
    "            )\n",
    "\n",
    "            generation_time.append(time.time() - start_time)\n",
    "\n",
    "            logits = outputs.logits[:, -1, :]\n",
    "\n",
    "            label = encodings.input_ids[:, idx + 1 : idx + 2].to(logits.device).view(-1)\n",
    "            neg_log_likelihood = loss_fn(logits, label)\n",
    "\n",
    "            # clean apple mps cache (for some reason it does not flush automatically)\n",
    "            if torch.backends.mps.is_available():\n",
    "                torch.mps.empty_cache()\n",
    "\n",
    "        nlls.append(neg_log_likelihood)\n",
    "        pbar.set_description(\n",
    "            f\"nll: {neg_log_likelihood.item():.2f}, ppl: {torch.exp(neg_log_likelihood).item():.2f}\"\n",
    "        )\n",
    "    global_nlls.append(nlls)\n",
    "    global_generation_time.append(generation_time)\n",
    "    global_past_key_values_size.append(past_key_values_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlls = torch.tensor(global_nlls).mean(dim=0)\n",
    "past_key_values = torch.tensor(global_past_key_values_size, dtype=torch.float64).mean(\n",
    "    dim=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_key_values_size[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(nlls)), torch.tensor(past_key_values_size))\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"KV-cache memory usage\")\n",
    "plt.xlabel(\"Input size in tokens\")\n",
    "plt.ylabel(\"Memory size in Bytes\")\n",
    "plt.grid(alpha=0.6, zorder=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = nlls\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(14, 10))\n",
    "ax[0].plot(\n",
    "    range(len(nlls)),\n",
    "    [t[: i + 1].mean() for i in range(len(nlls))],\n",
    ")\n",
    "# ax[0].axvline(\n",
    "#     x=model.config.max_position_embeddings,\n",
    "#     color=\"red\",\n",
    "#     linestyle=\"--\",\n",
    "#     alpha=1,\n",
    "#     label=\"Context Length\",\n",
    "# )\n",
    "ax[0].axvline(\n",
    "    x=kv_cache_size,\n",
    "    color=\"green\",\n",
    "    linestyle=\"--\",\n",
    "    alpha=1,\n",
    "    label=\"KV Cache Size\",\n",
    ")\n",
    "ax[0].set_ylabel(\"Log PPL\")\n",
    "ax[0].set_xlabel(\"Input size in tokens\")\n",
    "ax[0].grid(alpha=0.6, zorder=1)\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(\n",
    "    range(len(nlls)),\n",
    "    [(t[i]) for i in range(len(nlls))],\n",
    "    \"o\",\n",
    "    # color=\"red\",\n",
    "    # linewidth=0.1,\n",
    "    markersize=1,\n",
    ")\n",
    "# ax[1].axvline(\n",
    "#     x=model.config.max_position_embeddings,\n",
    "#     color=\"red\",\n",
    "#     linestyle=\"--\",\n",
    "#     alpha=0.6,\n",
    "#     label=\"Context Length\",\n",
    "# )\n",
    "ax[1].axvline(\n",
    "    x=kv_cache_size,\n",
    "    color=\"green\",\n",
    "    linestyle=\"--\",\n",
    "    alpha=1,\n",
    "    label=\"KV Cache Size\",\n",
    ")\n",
    "ax[1].set_ylabel(\"NLL (per token, not averaged)\")\n",
    "ax[1].set_xlabel(\"Input size in tokens\")\n",
    "ax[1].grid(alpha=0.6, zorder=1)\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT2 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(nlls)), generation_time, linewidth=0.5)\n",
    "plt.title(\"Generation time\")\n",
    "plt.xlabel(\"Input size in tokens\")\n",
    "plt.ylabel(\"Generation time in seconds\")\n",
    "plt.grid(alpha=0.6, zorder=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(nlls)), torch.tensor(past_key_values_size))\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"KV-cache memory usage\")\n",
    "plt.xlabel(\"Input size in tokens\")\n",
    "plt.ylabel(\"Memory size in Bytes\")\n",
    "plt.grid(alpha=0.6, zorder=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "t = torch.stack(nlls).cpu()\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(14, 10))\n",
    "ax[0].plot(\n",
    "    range(len(nlls)),\n",
    "    [t[: i + 1].mean() for i in range(len(nlls))],\n",
    ")\n",
    "ax[0].axvline(x=1024, color=\"red\", linestyle=\"--\", alpha=0.6, label=\"Context Length\")\n",
    "ax[0].set_ylabel(\"Log PPL\")\n",
    "ax[0].set_xlabel(\"Input size in tokens\")\n",
    "ax[0].grid(alpha=0.6, zorder=1)\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(\n",
    "    range(len(nlls)),\n",
    "    [(t[i]) for i in range(len(nlls))],\n",
    "    \"o\",\n",
    "    # color=\"red\",\n",
    "    # linewidth=0.1,\n",
    "    markersize=0.2,\n",
    ")\n",
    "ax[1].axvline(x=1024, color=\"red\", linestyle=\"--\", alpha=0.6, label=\"Context Length\")\n",
    "ax[1].set_ylabel(\"NLL (per token, not averaged)\")\n",
    "ax[1].set_xlabel(\"Input size in tokens\")\n",
    "ax[1].grid(alpha=0.6, zorder=1)\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "\n",
    "\n",
    "model_path = \"/Users/aszab/repos/models/gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path, output_attentions=True).to(device)\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(model_path)\n",
    "\n",
    "if model.config.pad_token_id is None:\n",
    "    model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "    \"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder.\",\n",
    "    return_tensors=\"pt\",\n",
    ").to(device)\n",
    "\n",
    "outputs = model(\n",
    "    **inputs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\"input_ids\": encodings[\"input_ids\"][:, :128].to(device)}\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.attentions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack(outputs.attentions).cpu().detach().numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_map(\n",
    "    attn: tuple[torch.Tensor], layer_num: int, head_num: int\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Retrieves the attention map for a specified layer and head from the model's attention outputs.\n",
    "\n",
    "    Args:\n",
    "        attn (tuple[torch.Tensor]): A tuple of attention tensors from the model's output.attentions.\n",
    "        layer_num (int): The index of the layer from which to retrieve the attention map.\n",
    "                         If -1, the attention maps across all layers are averaged.\n",
    "        head_num (int): The index of the head from which to retrieve the attention map.\n",
    "                        If -1, the attention maps across all heads are averaged.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The attention map for the specified layer and head.\n",
    "    \"\"\"\n",
    "    attn = torch.stack(attn).cpu().detach().numpy()\n",
    "    if layer_num == -1:\n",
    "        attn = attn.mean(axis=0, keepdims=True)\n",
    "        layer_num = 0\n",
    "\n",
    "    if head_num == -1:\n",
    "        attn = attn.mean(axis=2, keepdims=True)\n",
    "        head_num = 0\n",
    "\n",
    "    attn_map = attn[layer_num, 0, head_num, :, :]\n",
    "\n",
    "    return attn_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_map = get_attn_map(outputs.attentions, -1, -1)\n",
    "plt.plot(range(attn_map.shape[1]), attn_map[:, 0])\n",
    "plt.title(\"Proportion of first token attention across sequence lenghts\")\n",
    "plt.xlabel(\"Input length in tokens\")\n",
    "plt.ylabel(\"Propotion of attention given to the first token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_attn(\n",
    "    attn_map: np.ndarray, token_labels: list[str], log_scale: bool = False\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Visualizes an attention map with token labels.\n",
    "\n",
    "    Parameters:\n",
    "        attn_map (np.ndarray): The attention map to visualize. It is expected to be a 2D array.\n",
    "        token_labels (list[str]): A list of token labels corresponding to the attention map.\n",
    "        log_scale (bool, optional): If True, applies a logarithmic scale to the attention map values. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    fn = np.log if log_scale else lambda x: x\n",
    "\n",
    "    _, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    # mask for plotting the bad color for padding tokens (upper triangular part)\n",
    "    attn_map = np.ma.masked_where(attn_map == 0, attn_map)\n",
    "\n",
    "    cmap = plt.cm.coolwarm\n",
    "    cmap.set_bad(color=\"grey\")\n",
    "    ax.matshow(fn(attn_map), cmap=cmap)\n",
    "\n",
    "    ax.xaxis.set_label_position(\"bottom\")  # Move x-axis label to the bottom\n",
    "    ax.xaxis.tick_bottom()  # Ensure ticks are on the bottom\n",
    "    _ = ax.set_xticks(\n",
    "        range(len(inputs[\"input_ids\"][0])),\n",
    "        token_labels,\n",
    "        fontsize=9,\n",
    "        rotation=90,\n",
    "    )\n",
    "    _ = ax.set_yticks(\n",
    "        range(len(inputs[\"input_ids\"][0])),\n",
    "        token_labels,\n",
    "        fontsize=9,\n",
    "    )\n",
    "    ax.set_ylabel(\"Query token\", fontsize=12)\n",
    "    ax.set_xlabel(\"Key token\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_attn(\n",
    "    get_attn_map(outputs.attentions, 7, -1),\n",
    "    tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].cpu().detach().numpy()[0]),\n",
    "    True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_attn_layers(attn_map_lst: list[np.ndarray], log_scale: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Visualizes attention maps for each layer in a grid layout.\n",
    "\n",
    "    Parameters:\n",
    "        attn_map_lst (list[np.ndarray]): A list of attention maps, where each attention map is a 2D numpy array.\n",
    "        log_scale (bool): If True, applies a logarithmic scale to the attention maps for visualization. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    fn = np.log if log_scale else lambda x: x\n",
    "\n",
    "    n_cols = 4\n",
    "    n_rows = len(attn_map_lst) // n_cols\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(14, 10))\n",
    "\n",
    "    for i, attn_map in enumerate(attn_map_lst):\n",
    "        # mask for plotting the bad color for padding tokens (upper triangular part)\n",
    "        attn_map = np.ma.masked_where(attn_map == 0, attn_map)\n",
    "\n",
    "        cmap = plt.cm.coolwarm\n",
    "        cmap.set_bad(color=\"grey\")\n",
    "        axs[i // n_cols][i % n_cols].matshow(fn(attn_map), cmap=cmap)\n",
    "\n",
    "        axs[i // n_cols][i % n_cols].xaxis.set_label_position(\n",
    "            \"bottom\"\n",
    "        )  # Move x-axis label to the bottom\n",
    "        axs[i // n_cols][\n",
    "            i % n_cols\n",
    "        ].xaxis.tick_bottom()  # Ensure ticks are on the bottom\n",
    "\n",
    "        axs[i // n_cols][i % n_cols].set_title(f\"Layer {i}\")\n",
    "        axs[i // n_cols][i % n_cols].set_ylabel(\"Query token\", fontsize=10)\n",
    "        axs[i // n_cols][i % n_cols].set_xlabel(\"Key token\", fontsize=10)\n",
    "        fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_attn_layers(\n",
    "    [get_attn_map(outputs.attentions, i, -1) for i in range(12)], log_scale=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
